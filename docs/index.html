<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description"
          content="MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and Retention. A self-supervised learning framework for integrating histopathology images and transcriptomics.">
    <meta property="og:title"
          content="MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and Retention"/>
    <meta property="og:description"
          content="MIRROR is a novel self-supervised learning method that bridges histopathology and transcriptomics for improved cancer diagnosis and prognosis."/>
    <meta property="og:url" content="https://tianyifranklinwang.github.io/MIRROR"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/mirror_banner.png"/>
    <meta property="og:image:width" content="1280"/>
    <meta property="og:image:height" content="640"/>

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning">
    <meta name="twitter:description"
          content="A novel self-supervised learning framework integrating histopathology and transcriptomics for cancer research.">
    <meta name="twitter:image" content="static/image/mirror_banner.png">


    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords"
          content="Pathology, Whole Slide Image, WSI, Transcriptomics, Self-Supervised Learning, SSL, Multimodal Learning">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and
        Retention</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">MIRROR: Multi-Modal Pathological Self-Supervised
                        Representation Learning via Modality Alignment and Retention</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                <a href="https://github.com/TianyiFranklinWang" target="_blank">Tianyi Wang</a><sup>1</sup>,</span>
                        <span class="author-block">
                  <a href="https://dblp.org/pid/248/7360.html" target="_blank">Jianan Fan</a><sup>1</sup>,</span>
                        <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=ckAbIuYAAAAJ"
                       target="_blank">Dingxin Zhang</a><sup>1</sup>,
                  </span>
                        <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=JZzb8XUAAAAJ"
                       target="_blank">Dongnan Liu</a><sup>1</sup>,
                  </span>
                        <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=Usw1jeMAAAAJ"
                       target="_blank">Yong Xia</a><sup>2</sup>,
                  </span>
                        <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=4OqLaDwAAAAJ" target="_blank">Heng Huang</a><sup>3</sup>,
                  </span>
                        <span class="author-block">
                    and <a href="https://weidong-tom-cai.github.io" target="_blank">Weidong Cai</a><sup>1</sup>,
                  </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>The University of Sydney; <sup>2</sup>Northwestern Polytechnical University; <sup>3</sup>University of Maryland</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.00374" target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/TianyiFranklinWang/MIRROR" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.00374" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Histopathology and transcriptomics are fundamental modalities in cancer diagnostics,
                        encapsulating the morphological and molecular characteristics of the disease. Multi-modal
                        self-supervised learning has demonstrated remarkable potential in learning pathological
                        representations by integrating diverse data sources. Conventional multi-modal integration
                        methods primarily emphasize modality alignment, while paying insufficient attention to retaining
                        the modality-specific intrinsic structures. However, unlike conventional scenarios where
                        multi-modal inputs often share highly overlapping features, histopathology and transcriptomics
                        exhibit pronounced heterogeneity, offering orthogonal yet complementary insights. Histopathology
                        data provides morphological and spatial context, elucidating tissue architecture and cellular
                        topology, whereas transcriptomics data delineates molecular signatures through quantifying gene
                        expression patterns. This inherent disparity introduces a major challenge in aligning these
                        modalities while maintaining modality-specific fidelity. To address these challenges, we present
                        MIRROR, a novel multi-modal representation learning framework designed to foster both modality
                        alignment and retention. MIRROR employs dedicated encoders to extract comprehensive feature
                        representations for each modality, which is further complemented by a modality alignment module
                        to achieve seamless integration between phenotype patterns and molecular profiles. Furthermore,
                        a modality retention module safeguards unique attributes from each modality, while a style
                        clustering module mitigates redundancy and enhances disease-relevant information by modeling and
                        aligning consistent pathological signatures within a clustering space. Extensive evaluations on
                        The Cancer Genome Atlas (TCGA) cohorts for cancer subtyping and survival analysis highlight
                        MIRROR's superior performance, demonstrating its effectiveness in constructing comprehensive
                        oncological feature representations and benefiting the cancer diagnosis.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->


<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Introduction</h2>
                    <div class="content has-text-justified">
                        <img src="static/images/intro.png" alt="Introduction Image"/>
                        <p>
                            Unlike conventional methods that primarily emphasize capturing modality-shared information
                            while paying limited attention to modality-specific intrinsic structures and
                            indiscriminately learning both disease-relevant and irrelevant data with high redundancy,
                            MIRROR is specifically designed to balance modality alignment and retention.
                            By selectively preserving only disease-relevant features, it effectively mitigates
                            redundancy, thereby enhancing the model’s efficiency and representational capability.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero is-light">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Highlights</h2>
                    <div class="content has-text-justified">
                        <p>
                            The key contributions of this study are outlined as follows:
                        </p>
                        <ul>
                            <li><b>MIRROR</b>, a novel multi-modal self-supervised learning (SSL) model, is designed to
                                facilitate both modality alignment and retention, enabling the effective preservation of
                                both modality-shared and modality-specific information.
                            </li>
                            <li>A consistent pathological style-based clustering mechanism is introduced to preserve
                                disease-relevant information while mitigating redundancy.
                            </li>
                            <li>A novel preprocessing pipeline for transcriptomics data is proposed, integrating machine
                                learning-driven feature selection with biological knowledge to create refined
                                transcriptomics datasets.
                            </li>
                            <li>Comprehensive evaluations are conducted across diverse cohorts from the TCGA dataset,
                                focusing on cancer subtyping and survival analysis tasks, substantiating the superior
                                performance and effectiveness of the proposed approach.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <img src="static/images/mirror.png" alt="Architecture Image"/>
                        <p>
                        <p>Whole Slide Images (WSIs) are first partitioned into patches, which are processed through a
                            pre-trained patch encoder to extract patch-level feature representations. These features are
                            subsequently aggregated by the slide encoder to encapsulate slide-level characteristics into
                            a <i>[CLS]</i> token while projecting patch embeddings into the shared pathological latent
                            space.</p>

                        <p>Transcriptomics data are preprocessed using Recursive Feature Elimination (RFE) and manual
                            selection to identify high disease-related genes. The refined transcriptomic features are
                            then embedded into a compact representation and mapped into the shared latent space via an
                            RNA encoder.</p>

                        <p>An alignment module for each modality aligns representations across modalities, guided by the
                            alignment loss (<code>L<sub>align</sub></code>). Meanwhile, modality-specific retention
                            modules utilize perturbed inputs from both encoded patch and transcriptomics features to
                            capture modality-specific intrinsic structures, contributing to the retention loss
                            (<code>L<sub>retention</sub></code>).</p>

                        <p>Finally, both slide and transcriptomics representations are processed through a style
                            clustering module to learn and compare their pathological styles against learnable cluster
                            centers. The clustering loss (<code>L<sub>cluster</sub></code>) is used to align consistent
                            pathological styles within the cluster space.</p>

                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Qualitative Analysis</h2>
                </div>
            </div>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/wsi_attention_map.png" alt="Histopathology Attention Map"/>
                    <h2 class="subtitle has-text-centered">
                        Visualization of slide encoder attention weights on TCGA-BRCA, TCGA-NSCLC, TCGA-RCC and
                        TCGA-COADREAD. Regions exhibiting higher attention scores predominantly correspond to malignant,
                        tumor-bearing tissue, whereas areas with lower scores typically indicate normal regions.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/umap_transcriptomics.png" alt="UMAP Visualization"/>
                    <h2 class="subtitle has-text-centered">
                        Visualization of histopathology and transcriptomics features encoded by MIRROR on the
                        TCGA-NSCLC dataset, compared to those obtained using TANGLE. Pink dots represent samples from
                        TCGA-LUSC, while blue dots represent samples from TCGA-LUAD. MIRROR clearly yields
                        more distinct and well-aligned feature distributions.
                    </h2>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->


<section class="hero is-light">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Datasets</h2>
                    <div class="content has-text-justified">
                        <p>
                            We provide the processed transcriptomics data on
                            <a href="https://www.kaggle.com/datasets/wangtyi/mirror-pruned-tcga-rnaseq-data"
                               target="_blank" style="color: #007bff; text-decoration: none;">Kaggle</a> and
                            <a href="https://zenodo.org/records/15043064" target="_blank"
                               style="color: #007bff; text-decoration: none;">Zenodo</a>
                            for TCGA-BRCA, TCGA-NSCLC, TCGA-COADREAD, and TCGA-RCC.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@misc{wang2025mirrormultimodalpathologicalselfsupervised,
 title={MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and Retention},
 author={Tianyi Wang and Jianan Fan and Dingxin Zhang and Dongnan Liu and Yong Xia and Heng Huang and Weidong Cai},
 year={2025},
 eprint={2503.00374},
 archivePrefix={arXiv},
 primaryClass={cs.CV},
 url={https://arxiv.org/abs/2503.00374},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                                                                                target="_blank">Nerfies</a> project
                        page.
                        You are free to borrow the source code of this website, we just ask that you link back to this
                        page in the footer. <br> This website is licensed under a <a rel="license"
                                                                                     href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                                     target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for MIRROR
https://tianyifranklinwang.github.io/MIRROR -->
<script type="text/javascript">
    var sc_project = 13104519;
    var sc_invisible = 1;
    var sc_security = "90cf525d";
</script>
<script type="text/javascript"
        src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript>
    <div class="statcounter"><a title="Web Analytics"
                                href="https://statcounter.com/" target="_blank"><img class="statcounter"
                                                                                     src="https://c.statcounter.com/13104519/0/90cf525d/1/"
                                                                                     alt="Web Analytics"
                                                                                     referrerPolicy="no-referrer-when-downgrade"></a>
    </div>
</noscript>
<!-- End of Statcounter Code -->

<!-- End of Statcounter Code -->

</body>
</html>
